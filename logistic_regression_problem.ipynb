{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic-regression-problem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adshyam/Scholastic-Gradient-Descent-Practice/blob/main/logistic_regression_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2S-uFqwSvmg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUxLkBjISvmr"
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xexp5GYNSvmz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5008b821-246a-420c-adf8-dba37b269268"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54vJVc_KSvm9"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pKAn1-ASvm_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97pFTgrSvnE"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jykLIXZNSvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9209c9a3-bf6a-42e1-f052-423f3dc2e31d"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-M6oXASvnO"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShoMeocSvnP"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm6wi8L2SvnU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "96ceb0bd-2444-4160-9430-e08d3bc92a67"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4WFoxgASvnc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "f79427cc-8c75-4a57-eba0-141e381bb5d1"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 10 epochs took 0.08 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WaVxhGpSvnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e5635c73-b9b8-4054-bf5d-f061afdb4fa3"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su9e8fRLSvno"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcz5_UqCSvnq"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOBvEchCSvnr"
      },
      "source": [
        "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbn61rrXSvnt"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bA5yR3Svnv"
      },
      "source": [
        "- Load the datasets(train and test) into the respective arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdLeFU0USvnx"
      },
      "source": [
        "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmRH4UpSvny"
      },
      "source": [
        "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbZf9p5gSvn1"
      },
      "source": [
        "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytql9rnZ5dat"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpz8X5DMSvn2"
      },
      "source": [
        "w = np.zeros_like(X_train[0])\n",
        "b = 0\n",
        "eta0  = 0.0001\n",
        "alpha = 0.0001\n",
        "N = len(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrCqQrxESroQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7f3f9d4-433a-49e6-ae53-7a96dd6ff236"
      },
      "source": [
        " # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "def sigmoid(w,xi,b):\n",
        "  result= 1/(1+np.exp(-(np.dot(w,xi)+b)))\n",
        "  return result\n",
        "def logistic_loss(w,xi,b,yi):\n",
        "  total=0\n",
        "  for i in range(len(xi)):\n",
        "    total=total+ yi[i]*np.log(sigmoid(w,xi[i],b))+(1-yi[i])*np.log(1-sigmoid(w,xi[i],b ))\n",
        "  log_loss=total*(-1/len(xi))\n",
        "  return log_loss\n",
        "print(\"logistic loss for train data is \",logistic_loss(w,X_train,b,y_train))\n",
        "\n",
        "print(\"logistic loss for test data is \" ,logistic_loss(w,X_test,b,y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic loss for train data is  0.6931471805594285\n",
            "logistic loss for test data is  0.6931471805600673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Y5kVscSvn5"
      },
      "source": [
        "# now next task is to find the best w and b so that we minimize the loss \n",
        "# note minimizing loss is maxmizing the # of correctly guessed points by the logistic regression\n",
        "# best w and b can found by the technique of SGD\n",
        "# IN SGD technique, we update the value of w and be in each iteration so that after some iteration, we get optimal value of w and b \n",
        "# log loss in each iteration could be seen and will be decreasing logistic loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvHDjDWkZDtv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "e35fe709-27b3-41c5-ee88-8775fc997c1e"
      },
      "source": [
        "trainloss=[]\n",
        "testloss=[]\n",
        " \n",
        "def bestw(w,eta0, lamda, xi,yi,b):\n",
        "  result= w*(1-(eta0*lamda)/(len(xi))) +eta0*xi*(yi-sigmoid(w,xi,b))\n",
        "  return result\n",
        " \n",
        "def bestb(w,eta0,xi,yi,b):\n",
        "  result=b+eta0*(yi-sigmoid(w,xi,b))\n",
        "  return result\n",
        "updated_w=w\n",
        "updated_b=b\n",
        "for epoch in range(1,11):\n",
        "\n",
        "  for i in range(N):\n",
        "    updated_w=bestw(updated_w,eta0,alpha,X_train[i],y_train[i],updated_b)\n",
        "    updated_b=bestb(updated_w,eta0,X_train[i],y_train[i],updated_b)\n",
        "     \n",
        "  train_loss=logistic_loss(updated_w,X_train,updated_b,y_train)\n",
        "  trainloss.append(train_loss)\n",
        " \n",
        "  \n",
        "  test_loss=logistic_loss(updated_w,X_test,updated_b,y_test)\n",
        "  testloss.append(test_loss)\n",
        "  print(\"with b :\",updated_b)\n",
        "  print(\"the X train logistic loss in epoch \", epoch,\" :\",train_loss)\n",
        "  print(\"the X test logistic loss in epoch \", epoch,\" :\",test_loss)\n",
        "  print(\"*\"*70)\n",
        "  \n",
        "print(\"Final w is : \",updated_w)\n",
        "print(\"Final b is : \",updated_b)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with b : -0.31459326332545384\n",
            "the X train logistic loss in epoch  1  : 0.40403338932001165\n",
            "the X test logistic loss in epoch  1  : 0.4051791661729648\n",
            "**********************************************************************\n",
            "with b : -0.4709459802864583\n",
            "the X train logistic loss in epoch  2  : 0.3884044680473908\n",
            "the X test logistic loss in epoch  2  : 0.390081035010181\n",
            "**********************************************************************\n",
            "with b : -0.5798252917073647\n",
            "the X train logistic loss in epoch  3  : 0.38314938434256185\n",
            "the X test logistic loss in epoch  3  : 0.38502501943880163\n",
            "**********************************************************************\n",
            "with b : -0.6591552853297546\n",
            "the X train logistic loss in epoch  4  : 0.3807880436557241\n",
            "the X test logistic loss in epoch  4  : 0.38274338648211076\n",
            "**********************************************************************\n",
            "with b : -0.7177702984057924\n",
            "the X train logistic loss in epoch  5  : 0.37960715850231336\n",
            "the X test logistic loss in epoch  5  : 0.38159373102030814\n",
            "**********************************************************************\n",
            "with b : -0.7613464197167946\n",
            "the X train logistic loss in epoch  6  : 0.378985249930845\n",
            "the X test logistic loss in epoch  6  : 0.3809828818095057\n",
            "**********************************************************************\n",
            "with b : -0.7938588559234635\n",
            "the X train logistic loss in epoch  7  : 0.37864824659022384\n",
            "the X test logistic loss in epoch  7  : 0.3806487040949809\n",
            "**********************************************************************\n",
            "with b : -0.8181785915367921\n",
            "the X train logistic loss in epoch  8  : 0.3784624436518863\n",
            "the X test logistic loss in epoch  8  : 0.380462589783926\n",
            "**********************************************************************\n",
            "with b : -0.8364064459464011\n",
            "the X train logistic loss in epoch  9  : 0.37835882761875783\n",
            "the X test logistic loss in epoch  9  : 0.38035766961940026\n",
            "**********************************************************************\n",
            "with b : -0.8500905914247204\n",
            "the X train logistic loss in epoch  10  : 0.37830057167462394\n",
            "the X test logistic loss in epoch  10  : 0.38029797554381006\n",
            "**********************************************************************\n",
            "Final w is :  [-0.42313751  0.19095315 -0.14587075  0.33813665 -0.21195363  0.56523727\n",
            " -0.44537215 -0.09171355  0.21794613  0.16976406  0.19521275  0.0022948\n",
            " -0.0778107   0.33881492  0.02214337]\n",
            "Final b is :  -0.8500905914247204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yy8jWaa7Svn_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0af86daa-161d-44dc-c737-d0317abe78a0"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.42336692, -0.18547565,  0.14859036, -0.34144407,  0.2081867 ,\n",
              "         -0.56016579,  0.45242483,  0.09408813, -0.2092732 , -0.18084126,\n",
              "         -0.19705191, -0.00421916,  0.0796037 , -0.33852802, -0.02266721]]),\n",
              " array([0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4N4Xbr0otjV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8d2e4edf-cee2-43d8-84d9-8faf6cd85439"
      },
      "source": [
        "# these are the result I got after my Implementation\n",
        "print(updated_w-clf.coef_ )\n",
        "print(updated_b-clf.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00022941  0.0054775   0.0027196  -0.00330742 -0.00376692  0.00507149\n",
            "   0.00705267  0.00237458  0.00867294 -0.01107721 -0.00183915 -0.00192435\n",
            "   0.001793    0.0002869  -0.00052384]]\n",
            "[0.00304771]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5c2NNKp85_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "015c784d-8311-4766-ca08-ce63c97c023e"
      },
      "source": [
        "# now plotting the graph where x axis== epoch number, and y axis== train loss and test loss\n",
        "#reference for plotting:\n",
        "#https://matplotlib.org/gallery/api/two_scales.html\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create some mock data\n",
        "epoch=[i for i in range(1,16)]\n",
        " \n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('train loss', color=color)\n",
        "ax1.plot(trainloss, color=color)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('test loss', color=color)  # we already handled the x-label with ax1\n",
        "ax2.plot(testloss, color=color)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48gx6wQKSvoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a13d27ba-dc37-4ba2-89ea-7bfe4f7c24c1"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        if sigmoid(updated_w, X[i], updated_b) >= 0.5:\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95536\n",
            "0.95296\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}